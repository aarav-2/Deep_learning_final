{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 11:28:17.610229: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExecutionTime</th>\n",
       "      <th>ID</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-06 21:45:00+01:00</td>\n",
       "      <td>Fri00Q1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-06 22:00:00+01:00</td>\n",
       "      <td>Fri00Q1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-06 22:15:00+01:00</td>\n",
       "      <td>Fri00Q1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-06 22:30:00+01:00</td>\n",
       "      <td>Fri00Q1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-06 22:45:00+01:00</td>\n",
       "      <td>Fri00Q1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ExecutionTime       ID  high  low  close  volume\n",
       "0  2021-01-06 21:45:00+01:00  Fri00Q1   0.0  0.0    0.0     0.0\n",
       "1  2021-01-06 22:00:00+01:00  Fri00Q1   0.0  0.0    0.0     0.0\n",
       "2  2021-01-06 22:15:00+01:00  Fri00Q1   0.0  0.0    0.0     0.0\n",
       "3  2021-01-06 22:30:00+01:00  Fri00Q1   0.0  0.0    0.0     0.0\n",
       "4  2021-01-06 22:45:00+01:00  Fri00Q1   0.0  0.0    0.0     0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training data\n",
    "train_df = pd.read_csv('TRAIN_Reco_2021_2022_2023.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69805344, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after removing rows with 'volume' equal to 0.0: (4518103, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Check for rows where 'volume' is 0.0 and remove those rows\n",
    "train_df_cleaned = train_df[train_df['volume'] != 0.0]\n",
    "\n",
    "# Step 2: Print the shape of the cleaned dataframe\n",
    "print(\"Shape after removing rows with 'volume' equal to 0.0:\", train_df_cleaned.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.518103e+06</td>\n",
       "      <td>4.518103e+06</td>\n",
       "      <td>4.518103e+06</td>\n",
       "      <td>4.518103e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.544531e+02</td>\n",
       "      <td>1.481643e+02</td>\n",
       "      <td>1.512916e+02</td>\n",
       "      <td>7.615150e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.230588e+02</td>\n",
       "      <td>1.194735e+02</td>\n",
       "      <td>1.211441e+02</td>\n",
       "      <td>1.472579e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.318860e+03</td>\n",
       "      <td>-2.882710e+03</td>\n",
       "      <td>-2.318860e+03</td>\n",
       "      <td>2.500000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.796000e+01</td>\n",
       "      <td>7.410000e+01</td>\n",
       "      <td>7.600000e+01</td>\n",
       "      <td>3.750000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.176200e+02</td>\n",
       "      <td>1.127900e+02</td>\n",
       "      <td>1.151300e+02</td>\n",
       "      <td>1.900000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.978400e+02</td>\n",
       "      <td>1.910600e+02</td>\n",
       "      <td>1.944500e+02</td>\n",
       "      <td>7.775000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.999000e+03</td>\n",
       "      <td>7.655300e+03</td>\n",
       "      <td>9.000000e+03</td>\n",
       "      <td>1.201825e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               high           low         close        volume\n",
       "count  4.518103e+06  4.518103e+06  4.518103e+06  4.518103e+06\n",
       "mean   1.544531e+02  1.481643e+02  1.512916e+02  7.615150e+00\n",
       "std    1.230588e+02  1.194735e+02  1.211441e+02  1.472579e+01\n",
       "min   -2.318860e+03 -2.882710e+03 -2.318860e+03  2.500000e-02\n",
       "25%    7.796000e+01  7.410000e+01  7.600000e+01  3.750000e-01\n",
       "50%    1.176200e+02  1.127900e+02  1.151300e+02  1.900000e+00\n",
       "75%    1.978400e+02  1.910600e+02  1.944500e+02  7.775000e+00\n",
       "max    9.999000e+03  7.655300e+03  9.000000e+03  1.201825e+03"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get basic statistics about the dataset\n",
    "train_df_cleaned.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExecutionTime</th>\n",
       "      <th>ID</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2021-01-07 20:15:00+01:00</td>\n",
       "      <td>Fri00Q1</td>\n",
       "      <td>57.28</td>\n",
       "      <td>55.20</td>\n",
       "      <td>57.28</td>\n",
       "      <td>1.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2021-01-07 20:30:00+01:00</td>\n",
       "      <td>Fri00Q1</td>\n",
       "      <td>61.92</td>\n",
       "      <td>59.70</td>\n",
       "      <td>61.30</td>\n",
       "      <td>5.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2021-01-07 21:00:00+01:00</td>\n",
       "      <td>Fri00Q1</td>\n",
       "      <td>59.95</td>\n",
       "      <td>56.09</td>\n",
       "      <td>56.09</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2021-01-07 21:15:00+01:00</td>\n",
       "      <td>Fri00Q1</td>\n",
       "      <td>63.75</td>\n",
       "      <td>60.99</td>\n",
       "      <td>63.47</td>\n",
       "      <td>2.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2021-01-07 21:30:00+01:00</td>\n",
       "      <td>Fri00Q1</td>\n",
       "      <td>63.50</td>\n",
       "      <td>62.60</td>\n",
       "      <td>63.24</td>\n",
       "      <td>2.425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ExecutionTime       ID   high    low  close  volume\n",
       "90  2021-01-07 20:15:00+01:00  Fri00Q1  57.28  55.20  57.28   1.125\n",
       "91  2021-01-07 20:30:00+01:00  Fri00Q1  61.92  59.70  61.30   5.150\n",
       "93  2021-01-07 21:00:00+01:00  Fri00Q1  59.95  56.09  56.09   0.200\n",
       "94  2021-01-07 21:15:00+01:00  Fri00Q1  63.75  60.99  63.47   2.525\n",
       "95  2021-01-07 21:30:00+01:00  Fri00Q1  63.50  62.60  63.24   2.425"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows\n",
    "train_df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (4504663, 10, 4)\n",
      "Output shape: (4504663, 10, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the forecasting horizon and look-back window\n",
    "n_timesteps = 10  # Look-back window\n",
    "forecast_horizon = 10  # Number of steps to predict\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Loop through each asset and scale the features, then prepare sliding windows\n",
    "asset_ids = train_df_cleaned['ID'].unique()\n",
    "X, y = [], []\n",
    "\n",
    "for asset in asset_ids:\n",
    "    # Extract the data for this asset\n",
    "    asset_data = train_df_cleaned[train_df_cleaned['ID'] == asset][['high', 'low', 'close', 'volume']].values\n",
    "    \n",
    "    # Scale the data using MinMaxScaler\n",
    "    asset_data_scaled = scaler.fit_transform(asset_data)  # Scaling for each asset separately\n",
    "\n",
    "    # Create sliding windows for the asset\n",
    "    for i in range(len(asset_data_scaled) - n_timesteps - forecast_horizon):\n",
    "        X.append(asset_data_scaled[i:i+n_timesteps])  # Past `n_timesteps` for input\n",
    "        y.append(asset_data_scaled[i+n_timesteps:i+n_timesteps+forecast_horizon])  # Next 10 timesteps for output\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Check the shapes\n",
    "print(f\"Input shape: {X.shape}\")  # Expected shape: (samples, timesteps, features)\n",
    "print(f\"Output shape: {y.shape}\")  # Expected shape: (samples, forecast_horizon, features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saarthakkataria/anaconda3/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m112617/112617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m494s\u001b[0m 4ms/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 2/10\n",
      "\u001b[1m112617/112617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m484s\u001b[0m 4ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 3/10\n",
      "\u001b[1m112617/112617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3074s\u001b[0m 27ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 4/10\n",
      "\u001b[1m112617/112617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 5/10\n",
      "\u001b[1m112617/112617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 4ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 6/10\n",
      "\u001b[1m112617/112617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m510s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 7/10\n",
      "\u001b[1m112617/112617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 4ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 8/10\n",
      "\u001b[1m112617/112617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m484s\u001b[0m 4ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "\u001b[1m112617/112617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m493s\u001b[0m 4ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 10/10\n",
      "\u001b[1m112617/112617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 4ms/step - loss: 0.0025 - val_loss: 0.0024\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Step 1: Define the LSTM model\n",
    "model = Sequential()\n",
    "\n",
    "# Add LSTM layer\n",
    "model.add(LSTM(units=100, return_sequences=False, input_shape=(n_timesteps, 4)))  # 4 features: HLCV\n",
    "\n",
    "# Add Dense layer to output the predictions for the next 10 timesteps (4 features per timestep)\n",
    "model.add(Dense(forecast_horizon * 4))  # 4 features per timestep\n",
    "\n",
    "# Step 2: Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "# Step 3: Train the model\n",
    "history = model.fit(X, y.reshape(y.shape[0], -1), epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# The shape of y is reshaped to (samples, forecast_horizon * 4) for each prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">42,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,040</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m42,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m4,040\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">138,122</span> (539.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m138,122\u001b[0m (539.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,040</span> (179.84 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m46,040\u001b[0m (179.84 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">92,082</span> (359.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m92,082\u001b[0m (359.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model summary to see the architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_test: (14648236, 10, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the test data\n",
    "test_df = pd.read_csv('TEST_Reco_2024.csv')\n",
    "\n",
    "# Apply the scaler (fitted on training data) to scale the test data\n",
    "test_features = test_df[['high', 'low', 'close', 'volume']].values\n",
    "test_scaled = scaler.transform(test_features)\n",
    "\n",
    "# Create sliding windows for the test data\n",
    "X_test = []\n",
    "for i in range(len(test_scaled) - n_timesteps - forecast_horizon):\n",
    "    X_test.append(test_scaled[i:i+n_timesteps])\n",
    "\n",
    "# Convert to numpy array\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# Check the shape of X_test\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m457758/457758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m875s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Make predictions on the test data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Reshape the predictions to the correct format\n",
    "predictions = predictions.reshape(predictions.shape[0], forecast_horizon, 4)  # 4 features: HLCV\n",
    "\n",
    "# Step 5: Inverse transform the predictions back to the original scale\n",
    "predictions_original = np.array([scaler.inverse_transform(pred) for pred in predictions])\n",
    "\n",
    "# Step 6: Extract the actual HLCV values from the test data (assuming the same look-back period)\n",
    "y_test = test_df[['high', 'low', 'close', 'volume']].values[n_timesteps:n_timesteps+len(predictions)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in the test data: 14648256\n"
     ]
    }
   ],
   "source": [
    "# Check the total size of the test data for high, low, close, volume\n",
    "print(f\"Total number of rows in the test data: {test_df[['high', 'low', 'close', 'volume']].shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in test data: 14648256\n",
      "Required rows based on predictions: 146482360\n",
      "Size of y_test after slicing: 58592984\n",
      "y_test size 58592984 does not match expected 585929440\n"
     ]
    }
   ],
   "source": [
    "# Check total available test data size vs predictions size\n",
    "print(f\"Total rows in test data: {len(test_df)}\")\n",
    "print(f\"Required rows based on predictions: {len(predictions_original) * forecast_horizon}\")\n",
    "\n",
    "# Ensure slicing of y_test to fit exactly the available data\n",
    "available_size = min(len(test_df) - n_timesteps, len(predictions_original) * forecast_horizon)\n",
    "\n",
    "# Adjust y_test to only slice the available number of rows\n",
    "y_test = test_df[['high', 'low', 'close', 'volume']].values[n_timesteps:n_timesteps + available_size]\n",
    "\n",
    "print(f\"Size of y_test after slicing: {y_test.size}\")\n",
    "\n",
    "# Try reshaping with the adjusted size\n",
    "if y_test.size == len(predictions_original) * forecast_horizon * 4:\n",
    "    y_test_reshaped = y_test.reshape(predictions_original.shape[0], forecast_horizon, 4)\n",
    "    print(f\"Reshaped y_test: {y_test_reshaped.shape}\")\n",
    "else:\n",
    "    print(f\"y_test size {y_test.size} does not match expected {len(predictions_original) * forecast_horizon * 4}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_test_reshaped: (1464824, 10, 4)\n",
      "Shape of predictions_original: (1464824, 10, 4)\n"
     ]
    }
   ],
   "source": [
    "# Adjust the number of predictions to fit the available test data\n",
    "available_predictions = min(len(predictions_original), len(y_test) // forecast_horizon)\n",
    "\n",
    "# Slice the predictions and y_test to match\n",
    "predictions_original = predictions_original[:available_predictions]\n",
    "y_test = y_test[:available_predictions * forecast_horizon]\n",
    "\n",
    "# Reshape y_test to match the adjusted predictions\n",
    "y_test_reshaped = y_test.reshape(predictions_original.shape[0], forecast_horizon, 4)\n",
    "\n",
    "# Check the sizes\n",
    "print(f\"Shape of y_test_reshaped: {y_test_reshaped.shape}\")\n",
    "print(f\"Shape of predictions_original: {predictions_original.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of predictions_original: 14648236\n",
      "Forecast horizon: 10\n",
      "Required size for y_test: 146482360\n",
      "Shape of y_test before reshaping: (14648246, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of predictions_original: {len(predictions_original)}\")\n",
    "print(f\"Forecast horizon: {forecast_horizon}\")\n",
    "print(f\"Required size for y_test: {required_size}\")\n",
    "print(f\"Shape of y_test before reshaping: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sMAPE: 197.29436202318874%\n"
     ]
    }
   ],
   "source": [
    "# Define the sMAPE function\n",
    "def smape(y_true, y_pred):\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
    "    diff = np.abs(y_true - y_pred) / denominator\n",
    "    return np.mean(diff) * 100\n",
    "\n",
    "# Step 8: Calculate sMAPE between the predictions and actual values\n",
    "smape_value = smape(y_test_reshaped, predictions_original)\n",
    "print(f\"sMAPE: {smape_value}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is way better than from where we started indicating that the likely cause of the poor result in previous codes was due to the small scale of the data that wee trained on.\n",
    "Most liekly, if we use more data to train the LSTM(with null) model then it would perform better than this.\n",
    "\n",
    "As we have noticed the lack of computational power and less sub sampling model, we will try a different approach to optimise in the next model/\n",
    "We will use an advanced model but with focusing only on two assets and see if we can perform better. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
